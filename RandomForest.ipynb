{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/processed_dishes_v3.csv')\n",
    "data = pd.read_csv('data/processed_dishes_v4.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "data['menu_section'] = data['menu_section'].values.astype('str')\n",
    "data['dish_name'] = data['dish_name'].values.astype('str')\n",
    "data['cleaned_descriptions'] = data['cleaned_descriptions'].values.astype('str')\n",
    "data['full_description'] = data['full_description'].values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['full_description']\n",
    "Y = data.loc[:, 'contains_peanuts':'contains_meat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation\n",
    "\n",
    "Most classifiers and learning algorithms require the input data to be in numerical format rather than strings. Therefore, using a measure called Term Frequency, Inverse Document Frequency (tf-idf), I will convert the strings into vectors of integers. I have chosen a `min_df` value of 5, which means that a word must be present at least 5 times to be kept. This will help us remove any necessary words, especially since we've included the dish name as part of the features, and some names may be more fun than informative. I have also chosen the `ngram_range` to be `(1, 2)`, indicating that we want unigrams and bigrams. This is because certain food phrases may be more than 1 word long, and capturing those phrases is equally as important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, ngram_range=(1, 2))\n",
    "tfidf_features = tfidf.fit_transform(X).toarray()\n",
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_features, Y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "predictions= clf.predict(x_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "There are multiple hyperparameters that can be tuned, but I will be focusing on these:\n",
    "* `max_depth`: maximum depth of each tree\n",
    "* `n_estimators`: specifies the number of trees in the forest of the model\n",
    "* `min_samples_split`: the minimum number of samples required to split an internal leaf node\n",
    "* `min_samples_leaf`: the minimum number of samples required to be at a leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_range_2 = range(15, 76, 5)\n",
    "train_score_depth2, test_score_depth2 = validation_curve(\n",
    "                                RandomForestClassifier(random_state=42),\n",
    "                                X = x_train, y = y_train, \n",
    "                                param_name = 'max_depth', \n",
    "                                param_range = depth_range_2,\n",
    "                                n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean of training and test scores\n",
    "mean_train_score_depth2 = np.mean(train_score_depth2, axis = 1) \n",
    "mean_test_score_depth2 = np.mean(test_score_depth2, axis = 1) \n",
    "  \n",
    "# Plot mean accuracy scores for training and testing scores \n",
    "plt.plot(depth_range_2, mean_train_score_depth2,  \n",
    "     label = \"Training Score\", color = 'b') \n",
    "plt.plot(depth_range_2, mean_test_score_depth2, \n",
    "   label = \"Cross Validation Score\", color = 'g') \n",
    "  \n",
    "# Creating the plot \n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Max Depth\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "plt.tight_layout() \n",
    "plt.legend(loc = 'best') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees_range = range(100, 1001, 50)\n",
    "train_score_trees, test_score_trees = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = x_train, y = y_train, \n",
    "                                param_name = 'n_estimators', \n",
    "                                param_range = num_trees_range, \n",
    "                                n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean of training and test scores\n",
    "mean_train_score_trees = np.mean(train_score_trees, axis = 1) \n",
    "mean_test_score_trees = np.mean(test_score_trees, axis = 1) \n",
    "  \n",
    "# Plot mean accuracy scores for training and testing scores \n",
    "plt.plot(num_trees_range, mean_train_score_trees,  \n",
    "     label = \"Training Score\", color = 'b') \n",
    "plt.plot(num_trees_range, mean_test_score_trees, \n",
    "   label = \"Cross Validation Score\", color = 'g') \n",
    "  \n",
    "# Creating the plot \n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Num of Trees (n_estimators)\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "plt.tight_layout() \n",
    "plt.legend(loc = 'best') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_trees_range[np.argmax(mean_test_score_trees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_range = range(2, 11)\n",
    "train_score_split, test_score_split = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = x_train, y = y_train, \n",
    "                                param_name = 'min_samples_split', \n",
    "                                param_range = min_samples_range, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean of training and test scores\n",
    "mean_train_score_split = np.mean(train_score_split, axis = 1) \n",
    "mean_test_score_split = np.mean(test_score_split, axis = 1) \n",
    "  \n",
    "# Plot mean accuracy scores for training and testing scores \n",
    "plt.plot(min_samples_range, mean_train_score_split,  \n",
    "     label = \"Training Score\", color = 'b') \n",
    "plt.plot(min_samples_range, mean_test_score_split, \n",
    "   label = \"Cross Validation Score\", color = 'g') \n",
    "  \n",
    "# Creating the plot \n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Minimum Samples to Split an Internal Leaf Node (min_samples_split)\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "plt.tight_layout() \n",
    "plt.legend(loc = 'best') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_range[np.argmax(mean_test_score_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_leaf, test_score_leaf = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = x_train, y = y_train, \n",
    "                                param_name = 'min_samples_leaf', \n",
    "                                param_range = min_samples_range, \n",
    "                                n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean of training and test scores\n",
    "mean_train_score_leaf = np.mean(train_score_leaf, axis = 1) \n",
    "mean_test_score_leaf = np.mean(test_score_leaf, axis = 1) \n",
    "  \n",
    "# Plot mean accuracy scores for training and testing scores \n",
    "plt.plot(min_samples_range, mean_train_score_leaf,  \n",
    "     label = \"Training Score\", color = 'b') \n",
    "plt.plot(min_samples_range, mean_test_score_leaf, \n",
    "   label = \"Cross Validation Score\", color = 'g') \n",
    "  \n",
    "# Creating the plot \n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Minimum Samples at Leaf Node (min_samples_leaf)\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "plt.tight_layout() \n",
    "plt.legend(loc = 'best') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Random Forest Model\n",
    "With my hyperparameters, I will now try to build our model and see how it does on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42, max_depth=55, n_estimators=900, \n",
    "                             min_samples_split=4, min_samples_leaf=2)\n",
    "clf.fit(x_train, y_train)\n",
    "predictions= clf.predict(x_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Random Forest on Individual Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_for_ingredient(ingredient):\n",
    "    ing_Y = data[f'contains_{ingredient}'].to_numpy()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(tfidf_features, ing_Y, test_size=0.25, random_state=42)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RF_results(ingredient, n_estimators=100, min_samples_split=2, min_samples_leaf=2):\n",
    "    print(f'Creating model to predict contains_{ingredient}...')\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test_for_ingredient(ingredient)\n",
    "    clf = RandomForestClassifier(random_state=42, n_estimators=n_estimators,\n",
    "                                 min_samples_split=min_samples_split, \n",
    "                                 min_samples_leaf=min_samples_leaf, verbose=2, n_jobs=-1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print(f'Validating model to predict contains_{ingredient}...')\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = ['peanuts', 'egg', 'sesame', 'fish', 'shellfish', 'soy', 'meat']\n",
    "accuracies = []\n",
    "for ingredient in ingredients:\n",
    "    accuracies.append(get_RF_results(ingredient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters for Individual Random Forest Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparam(param, values, x_train, x_test, y_train, y_test):\n",
    "    train_score, test_score = validation_curve(\n",
    "                                RandomForestClassifier(random_state=42),\n",
    "                                X = x_train, y = y_train, \n",
    "                                param_name = param, \n",
    "                                param_range = values,\n",
    "                                n_jobs=-1, verbose=2)\n",
    "    # Calculating mean of training and test scores\n",
    "    mean_train_score = np.mean(train_score, axis = 1) \n",
    "    mean_test_score = np.mean(test_score, axis = 1) \n",
    "\n",
    "    print(\"Highest value occurred at \", np.argmax(test_score))\n",
    "    \n",
    "    # Plot mean accuracy scores for training and testing scores \n",
    "    plt.plot(values, mean_train_score,  \n",
    "         label = \"Training Score\", color = 'b') \n",
    "    plt.plot(values, mean_test_score, \n",
    "       label = \"Cross Validation Score\", color = 'g') \n",
    "\n",
    "    # Creating the plot \n",
    "    plt.title(\"Validation Curve with Random Forest\")\n",
    "    plt.xlabel(param) \n",
    "    plt.ylabel(\"Accuracy\") \n",
    "    plt.tight_layout() \n",
    "    plt.legend(loc = 'best') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = [15, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_estimators_range = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "min_samples_split_range = [2, 4, 6, 8, 10, 12]\n",
    "min_samples_leaf_range = [2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Up: Meat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) meat\n",
    "x_peanuts_train, x_peanuts_test, y_peanuts_train, y_peanuts_test = get_train_test_for_ingredient('meat')\n",
    "tune_hyperparam('max_depth', max_depth_range, x_peanuts_train, x_peanuts_test, y_peanuts_train, y_peanuts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_hyperparam('n_estimators', n_estimators_range, x_peanuts_train, x_peanuts_test, y_peanuts_train, y_peanuts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_hyperparam('min_samples_split', min_samples_split_range, x_peanuts_train, x_peanuts_test, y_peanuts_train, y_peanuts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_hyperparam('min_samples_leaf', min_samples_leaf_range, x_peanuts_train, x_peanuts_test, y_peanuts_train, y_peanuts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_accuracies = get_RF_results('meat', n_estimators=500, min_samples_split=9, min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meat_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) soy\n",
    "x_soy_train, x_soy_test, y_soy_train, y_soy_test = get_train_test_for_ingredient('soy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_hyperparam('n_estimators', n_estimators_range, x_soy_train, x_soy_test, y_soy_train, y_soy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
