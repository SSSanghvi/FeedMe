{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_dishes_v4.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "data['menu_section'] = data['menu_section'].values.astype('str')\n",
    "data['dish_name'] = data['dish_name'].values.astype('str')\n",
    "data['cleaned_descriptions'] = data['cleaned_descriptions'].values.astype('str')\n",
    "data['full_description'] = data['full_description'].values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['full_description']\n",
    "Y = data.loc[:, 'contains_peanuts':'contains_meat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation\n",
    "\n",
    "Most classifiers and learning algorithms require the input data to be in numerical format rather than strings. Therefore, using a measure called Term Frequency, Inverse Document Frequency (tf-idf), I will convert the strings into vectors of integers. I have chosen a `min_df` value of 5, which means that a word must be present at least 5 times to be kept. This will help us remove any necessary words, especially since we've included the dish name as part of the features, and some names may be more fun than informative. I have also chosen the `ngram_range` to be `(1, 2)`, indicating that we want unigrams and bigrams. This is because certain food phrases may be more than 1 word long, and capturing those phrases is equally as important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, ngram_range=(1, 2))\n",
    "tfidf_features = tfidf.fit_transform(X).toarray()\n",
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_for_ingredient(ingredient):\n",
    "    ing_Y = data[f'contains_{ingredient}'].to_numpy()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(tfidf_features, ing_Y, test_size=0.25, random_state=42)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SVM_predictions(ingredient): \n",
    "    print(f'Creating model to predict contains_{ingredient}...')\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test_for_ingredient(ingredient)\n",
    "    clf = LinearSVR(random_state=42, loss='squared_epsilon_insensitive')\n",
    "#     clf = SVR(kernel='linear')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print(f'Validating model to predict contains_{ingredient}...')\n",
    "    predictions = clf.predict(X_test)\n",
    "    prediction_classes = predictions > 0.5\n",
    "    accuracy = accuracy_score(Y_test, prediction_classes)\n",
    "    return clf, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = ['peanuts', 'egg', 'sesame', 'fish', 'shellfish', 'soy', 'meat']\n",
    "accuracies_SVM = []\n",
    "models_SVM = []\n",
    "predictions_SVM = []\n",
    "for ingredient in ingredients:\n",
    "    model, predictions, accuracy = get_SVM_predictions(ingredient)\n",
    "    models_SVM.append(model)\n",
    "    predictions_SVM.append(predictions)\n",
    "    accuracies_SVM.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN_predictions(ingredient, epochs=5):\n",
    "    print(f'Creating model to predict contains_{ingredient}...')\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test_for_ingredient(ingredient)\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(5787, input_shape=(11574,), activation='relu'),\n",
    "        layers.Dense(256),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "        metrics=['accuracy', tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()]\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs = epochs,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    model.save(\"nn/\" + ingredient)\n",
    "    \n",
    "    print(f'Validating model to predict contains_{ingredient}...')\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    prediction_classes = (predictions > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(Y_test, prediction_classes)\n",
    "\n",
    "    return model, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: generates nn models (can save models if you uncomment the model.save line)\n",
    "models_nn = []\n",
    "accuracies_nn = []\n",
    "predictions_nn = []\n",
    "for ingredient in ingredients:\n",
    "    model, predictions, accuracy = get_NN_predictions(ingredient, epochs=10)\n",
    "    models_nn.append(model)\n",
    "    predictions_nn.append(predictions)\n",
    "    accuracies_nn.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_NN_predictions('meat', epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2: if models are saved, this loads them from saved location  \n",
    "models_nn = []\n",
    "accuracies_nn = []\n",
    "predictions_nn = []\n",
    "for ingredient in ingredients:\n",
    "    print('loading ingredient ', ingredient)\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test_for_ingredient(ingredient)\n",
    "    model = tf.keras.models.load_model('nn/' + ingredient)\n",
    "    models_nn.append(model)\n",
    "    predictions = model.predict(X_test)\n",
    "    prediction_classes = (predictions > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(Y_test, prediction_classes)\n",
    "    predictions_nn.append(predictions)\n",
    "    accuracies_nn.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RF_predictions(ingredient):\n",
    "    print(f'Creating model to predict contains_{ingredient}...')\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test_for_ingredient(ingredient)\n",
    "    clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print(f'Validating model to predict contains_{ingredient}...')\n",
    "    prediction_classes = clf.predict(X_test)\n",
    "    predictions = clf.predict_proba(X_test)\n",
    "    accuracy = accuracy_score(Y_test, prediction_classes)\n",
    "    \n",
    "    return clf, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies_rf = []\n",
    "models_rf = []\n",
    "predictions_rf = []\n",
    "for ingredient in ingredients:\n",
    "    model, predictions, accuracy = get_RF_predictions(ingredient)\n",
    "    models_rf.append(model)\n",
    "    predictions_rf.append(predictions)\n",
    "    accuracies_rf.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"svm: \", accuracies_SVM)\n",
    "print(\"neural network: \", accuracies_nn)\n",
    "print(\"random forest: \", accuracies_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "predictions_SVM[0]\n",
    "for i in range(7): \n",
    "    single_prediction = []\n",
    "    for j in range(5000):\n",
    "        mean_pred = (sigmoid_v(predictions_SVM[i][j]) + predictions_nn[i][j] + predictions_rf[i][j][1]) / 3\n",
    "        single_prediction.extend(mean_pred)\n",
    "    final_predictions.append(single_prediction)\n",
    "final_predictions = (np.array(final_predictions) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_stats(i, ingredient):\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test_for_ingredient(ingredient)\n",
    "    accuracy = accuracy_score(Y_test, final_predictions[i])\n",
    "    print('accuracy =', accuracy)\n",
    "    classification_rep = classification_report(Y_test, final_predictions[i])\n",
    "    print(classification_rep)\n",
    "    CM = confusion_matrix(Y_test, final_predictions[i])\n",
    "    return accuracy, CM[1][0], CM[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accuracies = []\n",
    "final_fn = []\n",
    "final_fp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peanuts\n",
    "accuracy_peanuts, fn_peanuts, fp_peanuts = get_final_stats(0, 'peanuts')\n",
    "final_accuracies.append(accuracy_peanuts)\n",
    "final_fn.append(fn_peanuts)\n",
    "final_fp.append(fp_peanuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# egg\n",
    "accuracy_soy, fn_soy, fp_soy = get_final_stats(1, 'egg')\n",
    "final_accuracies.append(accuracy_soy)\n",
    "final_fn.append(fn_soy)\n",
    "final_fp.append(fp_soy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sesame\n",
    "accuracy_sesame, fn_sesame, fp_sesame = get_final_stats(2, 'sesame')\n",
    "final_accuracies.append(accuracy_sesame)\n",
    "final_fn.append(fn_sesame)\n",
    "final_fp.append(fp_sesame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fish\n",
    "accuracy_fish, fn_fish, fp_fish = get_final_stats(3, 'fish')\n",
    "final_accuracies.append(accuracy_fish)\n",
    "final_fn.append(fn_fish)\n",
    "final_fp.append(fp_fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shellfish\n",
    "accuracy_shellfish, fn_shellfish, fp_shellfish = get_final_stats(4, 'shellfish')\n",
    "final_accuracies.append(accuracy_shellfish)\n",
    "final_fn.append(fn_shellfish)\n",
    "final_fp.append(fp_shellfish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soy\n",
    "accuracy_soy, fn_soy, fp_soy = get_final_stats(5, 'soy')\n",
    "final_accuracies.append(accuracy_soy)\n",
    "final_fn.append(fn_soy)\n",
    "final_fp.append(fp_soy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meat\n",
    "accuracy_meat, fn_meat, fp_meat = get_final_stats(6, 'meat')\n",
    "final_accuracies.append(accuracy_meat)\n",
    "final_fn.append(fn_meat)\n",
    "final_fp.append(fp_meat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Ingredient': ingredients,\n",
    "    'Validation Accuracy': final_accuracies,\n",
    "    'Validation False Positives': final_fp, \n",
    "    'Validation False Negatives': final_fn\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
