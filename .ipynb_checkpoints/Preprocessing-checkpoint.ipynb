{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Objectives:\n",
    "- Remove records with no menu description. \n",
    "- Remove stop words from menu descriptions.\n",
    "- Remove punctuation from menu descriptions. \n",
    "- Convert menu descriptions to lower case.\n",
    "- Tokenize menu descriptions.\n",
    "- Add columns to indicate if certain ingredients are present in the dish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes = pd.read_csv('data/dishes-2020-09-15.csv')\n",
    "dish_ingredients = pd.read_csv('data/dish-ingredients-2020-09-15.csv')\n",
    "ingredients = pd.read_csv('data/ingredients-2020-09-15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dishes.shape)\n",
    "dishes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dish_ingredients.shape)\n",
    "dish_ingredients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ingredients.shape)\n",
    "ingredients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['menu_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with NaN menu description\n",
    "old_shape = dishes.shape\n",
    "dishes = dishes.dropna(subset=['menu_description'])\n",
    "print(f'Removing NaN Menu descriptions: {old_shape} -> {dishes.shape}')\n",
    "\n",
    "# Subsampling because there's just too much data to process. \n",
    "dishes = dishes.sample(n=20000, random_state=42)\n",
    "print(f'Randomly sampling 20K rows: -> {dishes.shape}')\n",
    "\n",
    "# Converting to lowercase\n",
    "dishes['menu_description'] = dishes['menu_description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def tokenize_and_process(desc):\n",
    "    tokens = nltk.word_tokenize(desc)\n",
    "    \n",
    "    # Removing stop words and punctuation from menu descriptions, and stem what's left.\n",
    "    tokens = [t for t in tokens if t not in stop_words and t.isalpha()]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['cleaned_descriptions'] = dishes['menu_description'].apply(tokenize_and_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredient_ids(ingredient_name):\n",
    "    # Returns a Series of ingredient_id's for a common name, e.g. 'peanut', or 'banana'. \n",
    "    return ingredients[ingredients['ingredient_name'].str.contains(ingredient_name)]['ingredient_id']\n",
    "\n",
    "def contains_ingredient(dish_id, ingredient):\n",
    "    ingredient_ids = set(get_ingredient_ids(ingredient))\n",
    "    dish_ingredient_id_list = set(dish_ingredients[dish_ingredients['dish_id'] == (dish_id)]['ingredient_id'])\n",
    "    return len(ingredient_ids.intersection(dish_ingredient_id_list)) > 0\n",
    "\n",
    "def contains_ingredients(dish_id, ingredients):\n",
    "    # Same as contains_ingredient, but for a list of ingredients. \n",
    "    ingredient_ids = set()\n",
    "    for i in ingredients:\n",
    "        ingredient_ids = ingredient_ids.union(set(get_ingredient_ids(i)))\n",
    "    dish_ingredient_id_list = set(dish_ingredients[dish_ingredients['dish_id'] == (dish_id)]['ingredient_id'])\n",
    "    return len(ingredient_ids.intersection(dish_ingredient_id_list)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_ids = dishes['dish_id']\n",
    "\n",
    "dishes['contains_peanuts'] = dish_ids.apply(lambda id: contains_ingredient(id, 'peanut'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dishes['contains_egg'] = dish_ids.apply(lambda id: contains_ingredient(id, ' egg')) # YES, THE SPACE IS NECESSARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_sesame'] = dish_ids.apply(lambda id: contains_ingredient(id, 'sesame'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_fish'] = dish_ids.apply(\n",
    "    lambda id: contains_ingredients(id, ['pollock', 'carp', 'cod', 'dogfish', 'mackerel', 'salmon', 'sole', 'tuna'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_shellfish'] = dish_ids.apply(lambda id: contains_ingredients(id, ['crab', 'lobster', 'shrimp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_soy'] = dish_ids.apply(lambda id: contains_ingredient(id, 'soy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_meat'] = dish_ids.apply(\n",
    "    lambda id: contains_ingredients(id, ['meat', 'fish', 'beef', 'steak', 'pork', 'bacon', 'chicken', 'duck', \n",
    "                                        'turkey', 'ham', 'salami', 'pheasant', 'goat', 'bison', 'boar'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the contains_* columns from booleans to integers\n",
    "for i in ['peanuts', 'egg', 'sesame', 'fish', 'shellfish', 'soy', 'meat']:\n",
    "    label = f'contains_{i}'\n",
    "    dishes[label] = dishes[label].astype(int)\n",
    "dishes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes.to_csv('data/processed_dishes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
