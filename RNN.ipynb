{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_dishes_v3.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "data['menu_section'] = data['menu_section'].values.astype('str')\n",
    "data['dish_name'] = data['dish_name'].values.astype('str')\n",
    "data['cleaned_descriptions'] = data['cleaned_descriptions'].values.astype('str')\n",
    "data['full_description'] = data['full_description'].values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = data.loc[:, 'dish_id':'cleaned_descriptions']\n",
    "features = data['full_description']\n",
    "Y = data.loc[:, 'contains_peanuts':'contains_meat'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_descriptions = features['cleaned_descriptions'].astype(str).apply(lambda s: s.split())\n",
    "split_descriptions = features.astype(str).apply(lambda s: s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "for d in split_descriptions:\n",
    "    [s.add(w) for w in d]\n",
    "print(f'Size of vocabulary: {len(s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation\n",
    "\n",
    "Most classifiers and learning algorithms require the input data to be in numerical format rather than strings. Therefore, using a measure called Term Frequency, Inverse Document Frequency (tf-idf), I will convert the strings into vectors of integers. I have chosen a `min_df` value of 5, which means that a word must be present at least 5 times to be kept. This will help us remove any necessary words, especially since we've included the dish name as part of the features, and some names may be more fun than informative. I have also chosen the `ngram_range` to be `(1, 2)`, indicating that we want unigrams and bigrams. This is because certain food phrases may be more than 1 word long, and capturing those phrases is equally as important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, ngram_range=(1, 2))\n",
    "tfidf_features = tfidf.fit_transform(features).toarray()\n",
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different approach: Tokenizer\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# description_only = features['cleaned_descriptions'].to_numpy()\n",
    "# tokenizer = Tokenizer(num_words=5252)\n",
    "# tokenizer.fit_on_texts(description_only)\n",
    "# encoded_description = tokenizer.texts_to_matrix(description_only, mode='count')\n",
    "# encoded_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(tfidf_features, Y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(3587, 128))\n",
    "model.add(layers.LSTM(128, dropout=0.2))\n",
    "model.add(layers.Dense(7, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tf.keras.preprocessing.sequence.pad_sequences(split_descriptions, dtype=object, padding='post', value=' ')\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=1, batch_size=128, shuffle=True, validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['chicken bacon ranch sauce mozzarella cheddar'] \n",
    "encoded_test = tokenizer.texts_to_matrix(test, mode='count')\n",
    "model.predict(encoded_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
