{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Objectives:\n",
    "- Remove records with no menu description. \n",
    "- Remove stop words from menu descriptions.\n",
    "- Remove punctuation from menu descriptions. \n",
    "- Convert menu descriptions to lower case.\n",
    "- Tokenize menu descriptions.\n",
    "- Add columns to indicate if certain ingredients are present in the dish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes = pd.read_csv('data/dishes-2020-09-15.csv')\n",
    "dish_ingredients = pd.read_csv('data/dish-ingredients-2020-09-15.csv')\n",
    "ingredients = pd.read_csv('data/ingredients-2020-09-15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dishes.shape)\n",
    "dishes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dish_ingredients.shape)\n",
    "dish_ingredients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ingredients.shape)\n",
    "ingredients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['menu_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with NaN menu description\n",
    "old_shape = dishes.shape\n",
    "dishes = dishes.dropna(subset=['menu_description'])\n",
    "print(f'Removing NaN Menu descriptions: {old_shape} -> {dishes.shape}')\n",
    "\n",
    "# Subsampling because there's just too much data to process. \n",
    "# dishes = dishes.sample(n=20000, random_state=42)\n",
    "# print(f'Randomly sampling 20K rows: -> {dishes.shape}')\n",
    "dishes = dishes.sample(n=8000, random_state=42)\n",
    "print(f'Randomly sampling 8K rows: -> {dishes.shape}')\n",
    "\n",
    "# Converting to lowercase\n",
    "dishes['menu_description'] = dishes['menu_description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def tokenize_and_process(desc):\n",
    "    tokens = nltk.word_tokenize(desc)\n",
    "    \n",
    "    # Removing stop words and punctuation from menu descriptions, and stem what's left.\n",
    "    tokens = [t for t in tokens if t not in stop_words and t.isalpha()]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['cleaned_descriptions'] = dishes['menu_description'].apply(tokenize_and_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Exploration of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dishes[dishes['dish_id'] == '8c310c8c-2461-4360-b10e-d21f331d8a4f']['cleaned_descriptions'].iloc[0])\n",
    "print(dish_ingredients[dish_ingredients['dish_id'] == '8c310c8c-2461-4360-b10e-d21f331d8a4f']['ingredient_id'])\n",
    "ingredients[ingredients['ingredient_id'] == 'a87ae1e6-c7a0-439c-a014-4e91c6c15343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dishes[dishes['dish_id'] == 'a0c36965-70c8-461d-bc05-23a913e5c87b']['cleaned_descriptions'].iloc[0])\n",
    "print(dish_ingredients[dish_ingredients['dish_id'] == 'a0c36965-70c8-461d-bc05-23a913e5c87b']['ingredient_id'])\n",
    "ingredients[ingredients['ingredient_id'] == 'c67ee877-2b18-4cc7-beb2-7372da69a3ed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes[dishes['dish_id'] == 'a0c36965-70c8-461d-bc05-23a913e5c87b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This discovery shows that our data isn't as reliable as we thought it would be. The dish_ingredients data says that the Chicken Bacon Ranch dish (dish_id = 8c310c8c-2461-4360-b10e-d21f331d8a4f) only has 1 ingredient associated with that, and that ingredient is salad dressing, ranch dressing, regular. \n",
    "\n",
    "In the next couple of steps, we will still use the dish_ingredients data but also process the descriptions to look for keywords that may help us identify which ingredients are in the dish. We believe that adding the description as part of the extraction for our labels will increase the accuracy of our model, since currently, we are having a lot of false negatives. Having a lot of false negatives isn't ideal in our situation; in fact, it would be better to have more false positives because it decreases the risk of someone having an allergic reaction or eating food that doesn't fit their diet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredient_ids(ingredient_name):\n",
    "    # Returns a Series of ingredient_id's for a common name, e.g. 'peanut', or 'banana'. \n",
    "    return ingredients[ingredients['ingredient_name'].str.contains(ingredient_name)]['ingredient_id']\n",
    "\n",
    "def contains_ingredient(dish_id, ingredient):\n",
    "    ingredient_ids = set(get_ingredient_ids(ingredient))\n",
    "    dish_ingredient_id_list = set(dish_ingredients[dish_ingredients['dish_id'] == (dish_id)]['ingredient_id'])\n",
    "    dish_description = dishes[dishes['dish_id'] == dish_id]['cleaned_descriptions']\n",
    "    in_description = dish_description.str.contains(ingredient).any()\n",
    "    return len(ingredient_ids.intersection(dish_ingredient_id_list)) > 0 or in_description\n",
    "\n",
    "def contains_ingredients(dish_id, ingredients):\n",
    "    # Same as contains_ingredient, but for a list of ingredients. \n",
    "    ingredient_ids = set()\n",
    "    dish_description = dishes[dishes['dish_id'] == dish_id]['cleaned_descriptions']\n",
    "    in_description = []\n",
    "    for i in ingredients:\n",
    "        ingredient_ids = ingredient_ids.union(set(get_ingredient_ids(i)))\n",
    "        in_description.append(dish_description.str.contains(i).any()) \n",
    "    dish_ingredient_id_list = set(dish_ingredients[dish_ingredients['dish_id'] == (dish_id)]['ingredient_id'])\n",
    "    return len(ingredient_ids.intersection(dish_ingredient_id_list)) > 0 or any(in_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_ids = dishes['dish_id']\n",
    "\n",
    "dishes['contains_peanuts'] = dish_ids.apply(lambda id: contains_ingredients(id, ['peanut', 'peanuts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dishes['contains_egg'] = dish_ids.apply(lambda id: contains_ingredients(id, [' egg', 'eggs', 'egg'])) # YES, THE SPACE IS NECESSARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_sesame'] = dish_ids.apply(lambda id: contains_ingredient(id, 'sesame'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_fish'] = dish_ids.apply(\n",
    "    lambda id: contains_ingredients(id, ['pollock', 'carp', 'cod', 'dogfish', 'mackerel', 'salmon', 'sole', 'tuna'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_shellfish'] = dish_ids.apply(lambda id: contains_ingredients(id, ['crab', 'lobster', 'shrimp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_soy'] = dish_ids.apply(lambda id: contains_ingredients(id, ['soy', 'tofu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes['contains_meat'] = dish_ids.apply(\n",
    "    lambda id: contains_ingredients(id, ['meat', 'fish', 'beef', 'steak', 'pork', 'bacon', 'chicken', 'duck', \n",
    "                                        'turkey', 'ham', 'salami', 'pheasant', 'goat', 'bison', 'boar'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the contains_* columns from booleans to integers\n",
    "for i in ['peanuts', 'egg', 'sesame', 'fish', 'shellfish', 'soy', 'meat']:\n",
    "    label = f'contains_{i}'\n",
    "    dishes[label] = dishes[label].astype(int)\n",
    "dishes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishes.to_csv('data/processed_dishes_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
